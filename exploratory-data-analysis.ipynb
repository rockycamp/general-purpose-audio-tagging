{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Freesound Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETE_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "import numpy as np\n",
    "np.random.seed(1001)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_noptebook\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/freesound-audio-tagging/train.csv\")\n",
    "test = pd.read_csv(\"../input/freesound-audio-tagging/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training examples=\", train.shape[0], \"  Number of classes=\", len(train.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_group = train.groupby(['label', 'manually_verified']).count()\n",
    "plot = category_group.unstack().reindex(category_group.unstack().sum(axis=1).sort_values().index)\\\n",
    "          .plot(kind='bar', stacked=True, title=\"Number of Audio Samples per Category\", figsize=(16,10))\n",
    "plot.set_xlabel(\"Category\")\n",
    "plot.set_ylabel(\"Number of Samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum samples per category = ', min(train.label.value_counts()))\n",
    "print('Maximum samples per category = ', max(train.label.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "fname = '../input/freesound-audio-tagging/audio_train/' + '00044347.wav'   # Hi-hat\n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scipy\n",
    "from scipy.io import wavfile\n",
    "rate, data = wavfile.read(fname)\n",
    "print(\"Sampling (frame) rate = \", rate)\n",
    "print(\"Total samples (frames) = \", data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data, '-', );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(data[:500], '.'); plt.plot(data[:500], '-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['nframes'] = train['fname'].apply(lambda f: wave.open('../input/freesound-audio-tagging/audio_train/' + f).getnframes())\n",
    "test['nframes'] = test['fname'].apply(lambda f: wave.open('../input/freesound-audio-tagging/audio_test/' + f).getnframes())\n",
    "\n",
    "_, ax = plt.subplots(figsize=(16, 4))\n",
    "sns.violinplot(ax=ax, x=\"label\", y=\"nframes\", data=train)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of audio frames, per label', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,5))\n",
    "train.nframes.hist(bins=100, ax=axes[0])\n",
    "test.nframes.hist(bins=100, ax=axes[1])\n",
    "plt.suptitle('Frame Length Distribution in Train and Test', ha='center', fontsize='large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_length = [707364, 353682, 138474, 184338]\n",
    "\n",
    "for length in abnormal_length:\n",
    "    abnormal_fnames = test.loc[test.nframes == length, 'fname'].values\n",
    "    print(\"Frame length = \", length, \" Number of files = \", abnormal_fnames.shape[0], end=\"   \")\n",
    "    fname = np.random.choice(abnormal_fnames)\n",
    "    print(\"Playing \", fname)\n",
    "    IPython.display.display(ipd.Audio( '../input/freesound-audio-tagging/audio_test/' + fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
